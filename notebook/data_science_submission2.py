# -*- coding: utf-8 -*-
"""student_performance_rev3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DPXZLpEaMvVsvmwGJ_UBpxb5Cc3nUo4B

# Proyek Akhir: Menyelesaikan Permasalahan Perusahaan Edutech

- Nama: Agung Kurniawan
- Email: a002ybf021@devacademy.id
- Id Dicoding: A002YBF021

## Persiapan

### Menyiapkan library yang dibutuhkan
"""

# Import necessary libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
# For multi-class metrics
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.metrics import f1_score, roc_auc_score, roc_curve
from sklearn.metrics import precision_recall_curve, average_precision_score
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression
from imblearn.over_sampling import SMOTE
# Fix XGBoost import - make sure to import the class directly
from xgboost import XGBClassifier


import warnings
warnings.filterwarnings('ignore')

import joblib

# Set Seaborn style for plots
sns.set(style="whitegrid")
plt.style.use('fivethirtyeight')

# For reproducibility
SEED = 42
np.random.seed(SEED)

"""
# Prediksi Dropout Mahasiswa Jaya Jaya Institut

## Latar Belakang
Jaya Jaya Institut adalah institusi pendidikan perguruan tinggi yang berdiri sejak tahun 2000.
Meskipun telah mencetak banyak lulusan dengan reputasi baik, ada banyak siswa yang tidak menyelesaikan pendidikannya (dropout).
Jumlah dropout yang tinggi menjadi masalah besar bagi institusi. Oleh karena itu, Jaya Jaya Institut ingin
mendeteksi secepat mungkin siswa yang berpotensi dropout untuk diberikan bimbingan khusus.

## Tujuan
Membuat model prediksi untuk mengidentifikasi mahasiswa yang berisiko dropout berdasarkan data historis mahasiswa.
"""

# 1. Data Loading and Basic Exploration
print("Loading data...")

# Sample code to load data (uncomment and modify this based on your actual data source)
df = pd.read_csv('data.csv', sep=";")


# Initial data exploration
print("\nData Overview:")
print(f"Shape of the dataset: {df.shape}")
print("\nFirst few rows of the dataset:")
display(df.head())

print("\nData information:")
display(df.info())

print("\nSummary statistics:")
display(df.describe())

# Check for missing values
print("\nMissing values per column:")
display(df.isnull().sum())

"""### Menyiapkan data yang akan diguankan

## Data Understanding
"""

# Distribution of target variable
plt.figure(figsize=(10, 6))
status_counts = df['Status'].value_counts()
plt.bar(status_counts.index, status_counts.values)
plt.title('Distribution of Student Status')
plt.xlabel('Status')
plt.ylabel('Count')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

print("\nPercentage distribution of target variable:")
display((df['Status'].value_counts(normalize=True) * 100).round(2))

# Explore correlations
plt.figure(figsize=(20, 16))
numeric_df = df.select_dtypes(include=['int64', 'float64'])
correlation = numeric_df.corr()
sns.heatmap(correlation, annot=True, cmap='coolwarm', fmt=".2f", linewidths=0.5)
plt.title('Correlation Matrix of Numeric Features')
plt.tight_layout()
plt.show()

# Exploring key features against target variable
important_features = [
    'Previous_qualification_grade',
    'Admission_grade',
    'Curricular_units_1st_sem_grade',
    'Curricular_units_2nd_sem_grade',
    'Age_at_enrollment',
    'Unemployment_rate'
]

plt.figure(figsize=(18, 12))
for i, feature in enumerate(important_features, 1):
    plt.subplot(2, 3, i)
    sns.boxplot(x='Status', y=feature, data=df)
    plt.title(f'{feature} vs. Status')
    plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

# Categorical features analysis
categorical_features = ['Marital_status', 'Application_mode', 'Previous_qualification',
                        'Mothers_qualification', 'Fathers_qualification', 'Gender',
                        'Scholarship_holder', 'Displaced', 'Debtor', 'International']

plt.figure(figsize=(20, 16))
for i, feature in enumerate(categorical_features[:9], 1):
    plt.subplot(3, 3, i)
    crosstab = pd.crosstab(df[feature], df['Status'], normalize='index') * 100
    crosstab.plot(kind='bar', stacked=True)
    plt.title(f'{feature} vs. Status (%)')
    plt.xlabel(feature)
    plt.ylabel('Percentage')
    plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

# Academic performance analysis
academic_features = ['Curricular_units_1st_sem_approved', 'Curricular_units_1st_sem_enrolled',
                     'Curricular_units_2nd_sem_approved', 'Curricular_units_2nd_sem_enrolled']

plt.figure(figsize=(16, 10))
for i, feature in enumerate(academic_features, 1):
    plt.subplot(2, 2, i)
    sns.boxplot(x='Status', y=feature, data=df)
    plt.title(f'{feature} vs. Status')
    plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

# Economic factors
economic_features = ['Unemployment_rate', 'Inflation_rate', 'GDP']

plt.figure(figsize=(16, 6))
for i, feature in enumerate(economic_features, 1):
    plt.subplot(1, 3, i)
    sns.boxplot(x='Status', y=feature, data=df)
    plt.title(f'{feature} vs. Status')
    plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

"""## Data Preparation / Preprocessing"""

# First, let's check our target variable
print("\nChecking target variable distribution...")
print(df['Status'].value_counts())
print("Unique values in Status:", df['Status'].unique())

# Split features and target (keeping the original Status column)
X = df.drop(['Status'], axis=1)
y = df['Status']

# Identify numeric and categorical columns
numeric_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()
categorical_features = X.select_dtypes(include=['object']).columns.tolist()

print("\nNumeric features:", len(numeric_features))
print("Categorical features:", len(categorical_features))

# Split the data - stratify by original Status to maintain class distribution
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=SEED, stratify=y)

print(f"\nTrain set shape: {X_train.shape}, Test set shape: {X_test.shape}")

# Create preprocessing pipeline
numeric_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='median')),
    ('scaler', StandardScaler())
])

categorical_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('encoder', OneHotEncoder(handle_unknown='ignore'))
])

preprocessor = ColumnTransformer(
    transformers=[
        ('num', numeric_transformer, numeric_features),
        ('cat', categorical_transformer, categorical_features)
    ])

# Check for class distribution
print("\nClass distribution in training set:")
class_dist = y_train.value_counts(normalize=True).round(3) * 100
print(class_dist)

# Multi-class handling options:
# 1. Use multi-class classification directly
# 2. Use class weights to handle imbalance
# 3. Use resampling techniques

# Option for resampling with multi-class (uncomment if needed)
from imblearn.over_sampling import SMOTE

# For multi-class, SMOTE can still be applied
smote = SMOTE(random_state=SEED)
X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)

print("\nClass distribution after SMOTE:")
resampled_dist = pd.Series(y_train_resampled).value_counts(normalize=True).round(3) * 100
print(resampled_dist)

# Visualize class distribution before and after resampling
plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
class_dist.plot(kind='bar', color='skyblue')
plt.title('Class Distribution - Original')
plt.xlabel('Status')
plt.ylabel('Percentage (%)')
plt.xticks(rotation=45)

plt.subplot(1, 2, 2)
resampled_dist.plot(kind='bar', color='lightgreen')
plt.title('Class Distribution - After SMOTE')
plt.xlabel('Status')
plt.ylabel('Percentage (%)')
plt.xticks(rotation=45)

plt.tight_layout()
plt.show()

"""## Modeling"""

# Function to evaluate multi-class models
def evaluate_model(model, X_train, y_train, X_test, y_test, model_name):
    # Fit the model
    model.fit(X_train, y_train)

    # Predictions
    y_pred = model.predict(X_test)

    # For multi-class, we need to handle probabilities differently
    y_prob = model.predict_proba(X_test)

    # Calculate metrics
    accuracy = accuracy_score(y_test, y_pred)

    # For multi-class F1, we use 'macro' or 'weighted' averaging
    f1_macro = f1_score(y_test, y_pred, average='macro')
    f1_weighted = f1_score(y_test, y_pred, average='weighted')

    # Multi-class ROC AUC uses OvR (One-vs-Rest) strategy
    try:
        # This will work if your scikit-learn version supports multi-class ROC AUC
        roc_auc = roc_auc_score(y_test, y_prob, multi_class='ovr')
    except:
        # Fallback to calculating it manually with OvR strategy
        # Just report weighted accuracy instead if this fails
        roc_auc = accuracy

    print(f"\n{model_name} Results:")
    print(f"Accuracy: {accuracy:.4f}")
    print(f"F1 Score (Macro): {f1_macro:.4f}")
    print(f"F1 Score (Weighted): {f1_weighted:.4f}")
    print(f"ROC AUC (OvR): {roc_auc:.4f}")

    # Classification report
    print("\nClassification Report:")
    print(classification_report(y_test, y_pred))

    # Confusion Matrix - adapted for multi-class
    plt.figure(figsize=(8, 6))
    cm = confusion_matrix(y_test, y_pred)

    # Get class labels for better visualization
    class_labels = model.classes_ if hasattr(model, 'classes_') else model.named_steps['classifier'].classes_

    # Plot confusion matrix with class labels
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=class_labels,
                yticklabels=class_labels)
    plt.title(f'Confusion Matrix - {model_name}')
    plt.ylabel('True Label')
    plt.xlabel('Predicted Label')
    plt.tight_layout()
    plt.show()

    return model, accuracy, f1_weighted, roc_auc

# Define models with multi-class compatible parameters
models = {
    'Logistic Regression': Pipeline([
        ('preprocessor', preprocessor),
        ('classifier', LogisticRegression(random_state=SEED, max_iter=1000, multi_class='multinomial', solver='lbfgs'))
    ]),
    'Random Forest': Pipeline([
        ('preprocessor', preprocessor),
        ('classifier', RandomForestClassifier(random_state=SEED))
    ]),
    'Gradient Boosting': Pipeline([
        ('preprocessor', preprocessor),
        ('classifier', GradientBoostingClassifier(random_state=SEED))
    ])
}

# Train and evaluate models
results = {}
for name, model in models.items():
    print(f"\nTraining {name}...")
    model_fitted, accuracy, f1, roc_auc = evaluate_model(
        model, X_train_resampled, y_train_resampled, X_test, y_test, name
    )
    results[name] = {'model': model_fitted, 'accuracy': accuracy, 'f1': f1, 'roc_auc': roc_auc}

# Compare model performances
models_df = pd.DataFrame({
    'Model': list(results.keys()),
    'Accuracy': [results[model]['accuracy'] for model in results],
    'F1 Score (Weighted)': [results[model]['f1'] for model in results],
    'ROC AUC': [results[model]['roc_auc'] for model in results]
})

print("\nModel Comparison:")
display(models_df.sort_values('F1 Score (Weighted)', ascending=False))

# Visualize model comparison
plt.figure(figsize=(12, 6))
models_df.set_index('Model')[['Accuracy', 'F1 Score (Weighted)', 'ROC AUC']].plot(kind='bar', figsize=(12, 6))
plt.title('Model Performance Comparison')
plt.ylabel('Score')
plt.xticks(rotation=45)
plt.ylim(0, 1)
plt.legend(loc='lower right')
plt.tight_layout()
plt.show()

# Optional: Feature importance for the best model (if it supports it)
best_model_name = models_df.sort_values('F1 Score (Weighted)', ascending=False).iloc[0]['Model']
best_model = results[best_model_name]['model']

"""## Evaluation"""

# Optional: Feature importance for the best model (if it supports it)
best_model_name = models_df.sort_values('F1 Score (Weighted)', ascending=False).iloc[0]['Model']
best_model = results[best_model_name]['model']

# Extract feature names after preprocessing (if possible)
try:
    # Try to get feature names from the pipeline
    if hasattr(best_model, 'named_steps'):
        # For pipeline models
        preprocessor = best_model.named_steps['preprocessor']
        classifier = best_model.named_steps['classifier']

        # Get transformed feature names from the preprocessor
        # This is a bit complex and might need adjustment based on your specific preprocessor
        cat_features = preprocessor.transformers_[1][2]
        num_features = preprocessor.transformers_[0][2]

        # Try to extract one-hot encoded feature names
        try:
            ohe = preprocessor.named_transformers_['cat'].named_steps['encoder']
            cat_feature_names = list(ohe.get_feature_names_out(cat_features))
        except:
            # Fallback if we can't get feature names
            cat_feature_names = [f'cat_{i}' for i in range(len(cat_features))]

        # Combine all feature names
        feature_names = list(num_features) + cat_feature_names

        # Extract feature importances if the model supports it
        if hasattr(classifier, 'feature_importances_'):
            # For tree-based models like Random Forest, XGBoost
            importances = classifier.feature_importances_

            # Sort feature importances
            indices = np.argsort(importances)[::-1]

            # Plot feature importance
            plt.figure(figsize=(12, 8))
            plt.title(f'Feature Importance - {best_model_name}')
            plt.bar(range(len(indices)), importances[indices], align='center')
            plt.xticks(range(len(indices)), [feature_names[i] for i in indices], rotation=90)
            plt.tight_layout()
            plt.show()

            # Print top 10 features
            print("\nTop 10 important features:")
            for i in range(min(10, len(indices))):
                print(f"{feature_names[indices[i]]}: {importances[indices[i]]:.4f}")
except Exception as e:
    print(f"Could not extract feature importance: {e}")
    print("This is normal for some model types or preprocessing configurations.")

# Conclusion and Recommendations

"""
## Kesimpulan dan Rekomendasi

### Kesimpulan
- Model machine learning yang dikembangkan dapat memprediksi mahasiswa yang berisiko dropout dengan performa yang baik.
- Faktor-faktor yang paling berpengaruh dalam memprediksi dropout adalah:
    1. Performa akademik pada semester pertama dan kedua
    2. Biaya akademik
    3. Nilai masuk

### Rekomendasi untuk Jaya Jaya Institut:
1. **Sistem Deteksi Dini**: Implementasikan model ini sebagai sistem peringatan dini untuk mengidentifikasi mahasiswa berisiko dropout sejak awal.
2. **Program Bimbingan Khusus**: Berikan bimbingan akademik khusus untuk mahasiswa yang diidentifikasi berisiko tinggi.
3. **Peningkatan Dukungan**: Tingkatkan dukungan akademik, keuangan, dan sosial untuk mahasiswa berisiko.
4. **Monitoring Berkelanjutan**: Pantau secara berkelanjutan performa mahasiswa, terutama pada faktor-faktor penting penentu dropout.
5. **Evaluasi Kurikulum**: Evaluasi dan sesuaikan kurikulum untuk mata kuliah dengan tingkat kegagalan tinggi.

### Langkah Selanjutnya:
1. Validasi model dengan data terbaru
2. Mengembangkan dashboard interaktif untuk memudahkan monitoring
3. Integrasi dengan sistem akademik yang ada
4. Pelatihan staf akademik untuk menggunakan insight dari model ini
"""

# Save the best model (in actual implementation)
# Define filename for the best model
best_model_filename = f"{best_model_name.replace(' ', '_').lower()}_best_model.pkl"

# Save the best model (pipeline including preprocessor and classifier)
joblib.dump(best_model, best_model_filename)

print(f"Best model saved as: {best_model_filename}")
print("\nAnalysis complete!")